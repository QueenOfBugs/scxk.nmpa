* 爬虫练手之化妆品许可信息爬取

** 目标网址：
   - 网站地址:
     http://scxk.nmpa.gov.cn:81/xk/
   - 详情页地址:
     http://scxk.nmpa.gov.cn:81/xk/itownet/portal/dzpz.jsp?id=ed59438f34ae47e794f4c7ee5137c1f7

** 目标数据:
   所有详情页的数据,当前 共 5K+ 的数据.

** 网站分析:
   网站每个列表页最多一页 ~15~ 条数据,能通过列表页跳转到详情页.
   每个列表页的数据都是 POST 请求返回的响应数据.
   POST 请求的网址:http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsList
   POST 请求的表单数据:
   | 字段             | 值      | 含义                                               |
   | "on":            | "true", | 固定值                                             |
   | "page":          | "4",    | 分页数                                             |
   | "pageSize":      | "15",   | 每页数据条数,固定                                  |
   | "productName":   | "",     | 查询关键词                                         |
   | "conditionType": | "1",    | 查询范围:1--许可证编号,2--企业名称,3--社会信用代码 |
   | "applyname":     | "",     | 为空,固定值                                        |
   | "applysn":       | ""      | 为空,固定值                                        |
   每个详情页的网址只有一个 ~id~ 参数不一样,因此很容易判断出 ~id~ 就是获取详情页数据
   的重要参数,分析详情页的网络请求后得知详情页的数据也是通过 POST 请求获取得到的.
   POST 请求网址:http://scxk.nmpa.gov.cn:81/xk/itownet/portalAction.do?method=getXkzsById
   POST 请求表单:
    | 字段  | 值                                 |
    | "id": | "b419d634592c4331822ff73cd5a12f99" |
   有了这两个请求地址,就应该能获取到该目标网站的所有目标数据.

** 数据分析
   经过测试,按照上面网站分析的思路,通过分页请求的方式爬取数据,实际上只能获取到前
   50页或者200页之后的数据,服务器不允许字段 ~page~ 大于50或者小于200的请求.但网站
   有查询接口,就是上面获取列表页信息的网址,只需要更改 ~productname~ 字段就可以进行
   查询操作.经过分析,可 查询的三个字段,许可证编号,企业名称和社会信用代码,只有许
   可证编号有一定规律,可 以通过其规律来分次获取详情数据,推测的许可证编号的格式:
   ~{省份简称}妆{年份}{编号}~ 例如 "粤妆20160001";重要的一点是这个查询接口支持模
   糊查询,我们使用 "粤妆 2016"作为关键词查询的话,可以查到整个2016年份,广东省药品
   监督管理局发放的许可证.因为每次获取列表页的数据都会返回数据的总条数,所以我们
   可以以总条数为基线条件,通 过遍历编号的方式来获取少于50页的列表页数据,进而获取
   整个网站的数据. 例如:通过查询关键字 "粤妆2017",可以得到当年广东药品监督管理局
   2017年发放了544 条数据,是小于 50*15=750 条数据的,所以可以直接请求分页来获取数
   据.根据上面的分析,我们需要 省份的简称列表,年份信息以及编号规律这三个数据就可
   以获得所有目标数据了.

*** 测试代码
   [[file:scxk_test.py::测试网站布局和数据组成以及反爬措施.][scxk_test.py]]
   测试结果:
   - 网站返回的查询结果的数据总条数比不使用查询时的数据少了一条,可能的原因:
     - 某一个数据的格式与我们猜测的不一致
     - 网站数据明显是从数据库里取出来的,可能 ~count() 和 ~count() where ...~ 的数据
       本就有差异.
   - 超过50页的区域只有粤,其实只需要对粤地区的数据进行关键字查询.
   - 每条详情页的响应数据在

** 编码思路
   按省份区域进行数据的抓取,对于数据页数少于50的区域,直接发起分页请求,获取所有数
   据,对于数据页数多于50的区域,先根据年份查询,再看是否多于50页,如果多于就再根据
   编号查询.
   首先,需要两个函数,第一个函数用来获取详情页的 ~id~, 第二个函数,根据第一个函数返
   回的 id 值发起POST 请求,获取详情页信息;
   还需要一个 main() 函数处理查询关键字和数据存储操作.

** 编码流程
   1. 省份简称列表 ~cities~,用来拼接查询关键字.
   2. 定义一个函数 ~get_all_id(page) -> list~ 获取 page 页的 id 列表
   3. 定义一个函数 ~get_detail(id)~ 根据 id 获取详情页数据,并将数据以 json 字典形
      式返回.
   4. 定义一个函数 ~save_data(fp, data)~ 负责将字典形式的数据存储到文件中(最终这个
      函数的功能直接在 main() 里使用 json 模块完成了.)
   5. 定义一个函数 ~main()~ 遍历 ~cities~, 拼接生成查询关键字:
      1. 遍历结束,退出 ~main()~ 函数,遍历未结束,进行第2步.
      2. 使用关键字 ~{city}妆~ 进行查询,获取数据总页数 result["pageCount"], 总页数
         小于或等于50,进行第3步,否则进行第4步.
      3. 使用 ~get_all_id(page)~ 获取所有 id 的列表,再遍历 id 列表,用 ~get_detail()~ 函数获取详情
         信息,最后将返回的数据全存到 ~data.json~ 中去,遍历完成后返回第一步.
      4. 使用关键字 ~{city}妆{year}~ 例如 ~粤妆2016~ 进行查询,遍历年份从 2016 到
         2022 年,检查总页数是否大于50,是则进行第五步,并记录下数据总条数 result["totalCount"],反之则回到第3步.遍历完成后返回第一步.
      5. 以关键字 ~{city}妆{year}{num}~ 为关键字进行查询, num 从 00开始遍历,到99结束,
         实际上是肯定没有这么多的,所以要记录一个总数,当总数等于第四步记录的
         result["totalCount"] 时,退出 num 的遍历,反之则进行第三步.
